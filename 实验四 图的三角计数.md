# 实验四 图的三角计数

## 1. 实验要求

### 1.1 实验背景

  图的三角形计数问题是一个基本的图计算问题，是很多复杂网络分析（比如社交网络分析）的基础。

### 1.2 实验任务

  一个社交网络可以看做是一张图（理算数学中的图）。社交网络中的人对应于图的顶点，对应于图中的顶点；社交网络中的人际关系对应于图中的边。本次实验任务中，我们只考虑一种关系——用户之间的关注关系。假设“王五”在Twitter中关注了“李四”，则在社交网络图中，有一条对应的从“王五”指向“李四”的有向边，图1展示了一个简单的社交网络图，人之间的关注关系通过图中的有向边标识了出来。本次实验任务就是在给定的社交网络图中，统计图中所有三角形的数量。在统计前，需要进行有向边到无向边的转化，依据如下逻辑转换：

![](C:\Users\28096\Desktop\2018-11-19_21-05-04.png)

  "A->B"表示从顶点A到顶点B的一条有向边。A-B表示顶点A和顶点B之间有一条无向边。一个示例见图1，图1右侧的图就是左侧的图去除边方向后对应的无向图。

  请在无向图上统计三角形的个数。在图一的例子中一共有三个三角形。

![](C:\Users\28096\Desktop\2018-11-19_21-11-28.png)



## 2.实验设计说明

### 2.1 主要设计思路 

  考虑到三角形计数，将与选定点相连的边设为“+”，与选定点相连的两个点之间若有边设为“-”，最后计算“-”的个数即可。

### 2.2 算法设计

  使用MapReduce来实现这个算法， 可以通过使用三次Job来实现。

  第一次， Map读入数据，将数据整理一下，例如：读入A，B，保证A<B，输出键值对为（A+B， +），然后Reduce去重。

  第二次，Map读入第一次Reduce后的数据，将数据键值对变为（A，B），第二次Reduce将与指定点相连的边的值设为"+",例如存在AB，AC两条边，则存入（A+B，+）和（A+C，+）两个键值对，然后检查是否有BC边，若有记为（B+C，-)并保证B <C.

第三次，这次Map什么都不做，Reduce需要计算三角形个数，对于一条边，若有"+"说明存在着条边，这时可以计算”-“的个数，即为包含这条边的三角形个数，将所有的count加在一起即可以计算出三角形个数。

| Class    | Input Key    | Input Value | Output Key | Output Value |
| -------- | ------------ | ----------- | ---------- | ------------ |
| Map_1    | Object       | Text        | Text       | Text         |
| Reduce_1 | Text         | Text        | Text       | Text         |
| Map_2    | LongWritable | Text        | Text       | Text         |
| Reduce_2 | Text         | Text        | Text       | Text         |
| Map_3    | LongWritable | Text        | Text       | Text         |
| Reduce_3 | Text         | Text        | Text       | Text         |

### 2.3 代码实现

#### 2.3.1 Map_1

```java
public class Map_1 extends Mapper<Object, Text, Text, Text> {
    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
        String[] line = value.toString().split(" ");
        String a = new String(line[0]);
        String b = new String(line[1]);
        if(a.compareTo(b) > 0) {//保证A<B
            context.write(new Text(b + "+" + a), new Text("+"));
        }else if(a.compareTo(b) < 0) {
            context.write(new Text(a + "+" + b), new Text("+"));
        }else {
            return ;
        }
    }
}
```

#### 2.3.2 Reduce_1

```java
public class Reduce_1 extends Reducer<Text, Text, Text, Text> {
    public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {
        context.write(key, new Text("+"));//去重
    }
}
```

#### 2.3.3 Map_2

```java
public class Map_2 extends Mapper<LongWritable ,Text ,Text, Text> {
    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        StringTokenizer st = new StringTokenizer(value.toString());
        String[] line = st.nextToken().toString().split("\\+");
        context.write(new Text(line[0]), new Text(line[1]));
    }
}
```

#### 2.3.4 Reduce_2

```java
public class Reduce_2 extends Reducer<Text, Text, Text, Text> {
    public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {
        ArrayList<String> array = new ArrayList<String>();
        for(Text value : values) {
            array.add(value.toString());
            context.write(new Text((key.toString() + "+" + value.toString())), new Text("+"));
        }
        for(int i=0; i<array.size(); i++) {
            for(int j=i+1; j<array.size(); j++) {
                String a = array.get(i);
                String b = array.get(j);
                if(a.compareTo(b) < 0) {
                    context.write(new Text(a + "+" + b), new Text("-"));//"-"表示邻边关系
                }
                else {

                    context.write(new Text(b + "+" + a), new Text("-"));
                }
            }
        }
    }
}
```



#### 2.3.5 Map_3

```java
public class Map_3 extends Mapper<LongWritable, Text, Text, Text> {
    public void map(LongWritable key, Text values, Context context) throws IOException, InterruptedException {
        StringTokenizer st=new StringTokenizer(values.toString());
        context.write(new Text(st.nextToken()), new Text(st.nextToken()));//什么都不做
    }
}
```



#### 2.3.6 Reduce_3

```java
public class Reduce_3 extends Reducer<Text, Text,Text, Text> {
    private static int result = 0;
    public void cleanup(Context context) throws IOException, InterruptedException {
        context.write(new Text("Result: "), new Text("" + result));//输出结果
    }
    public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {
        boolean flag = false;
        int count = 0;
        for(Text value: values) {
            if(value.toString().equalsIgnoreCase("+")){//判断是否有这条边
                flag = true;
            }else if(value.toString().equalsIgnoreCase("-")) {//计数
                count ++;
            }
        }
        if(flag) {
            result += count;
        }
    }
}
```



## 3.结果

### 3.1 输出结果

| 数据集  | 三角形个数 | Driver程序在集群上的运行时间（秒） |
| ------- | ---------- | ---------------------------------- |
| Twitter | 13082506   | 245                                |

* Twitter运行截图（/user/2018st18/exp4/result3

  ![](C:\Users\28096\Desktop\MapReduce4\2018-11-19_16-25-32.png)

* Google+运行截图

  ![]()

### 3.2 作业截图

#### 3.2.1Twitter作业截图



![](E:\MapReduce4\MapReduce4\all.png)



![](E:\MapReduce4\MapReduce4\Job1.png)

![](E:\MapReduce4\MapReduce4\Job1_1.png)

![](E:\MapReduce4\MapReduce4\Job2.png)

![](E:\MapReduce4\MapReduce4\Job2_1.png)

![](E:\MapReduce4\MapReduce4\Job3.png)

![](E:\MapReduce4\MapReduce4\Job3_1.png)

## 4小结

​	本次实验使用了三个job来实现，第三次job的map阶段什么都没有做，浪费了很多时间，如果深入的话，可以减少一次job，还有很多MapReduce的技巧没有用上，比如combiner和Partioner，这些可以更快的提高效率。

## 附录：JAR包的运行方式

```shell
hadoop jar TwitterGraph.jar Assignment //完成Twitter
```

